# Feature Specification: Document Ingestion Pipeline

**Feature Branch**: `002-document-ingestion`  
**Created**: 2024-12-14  
**Status**: Draft  
**Input**: User description: "Build document ingestion from existing implementation to enhance Q&A feature quality. Currently supports PDF, DOC, text files with future support for YouTube videos."

## User Scenarios & Testing _(mandatory)_

### User Story 1 - Extract Text from Uploaded Documents (Priority: P1)

As a student, I want the system to automatically extract readable text from my uploaded study materials (PDF, DOC, DOCX, TXT files) so that the content becomes searchable and usable for AI-powered Q&A.

**Why this priority**: Text extraction is the foundational step of the ingestion pipeline. Without extracted text, no downstream features (chunking, embedding, Q&A) can function. This directly enables the core value proposition.

**Independent Test**: Can be tested by uploading a PDF document and verifying that the full text content is extracted and stored. The extracted text should be viewable and match the original document content.

**Acceptance Scenarios**:

1. **Given** a student has uploaded a PDF file to their space, **When** the background extraction task runs, **Then** the document's text content is extracted and stored in the database
2. **Given** a student has uploaded a DOCX file, **When** extraction completes, **Then** all text including formatted content (headings, paragraphs, lists) is preserved in plain text format
3. **Given** a student uploads a file that cannot be parsed (e.g., corrupted PDF), **When** extraction fails, **Then** the document is marked with an error status and the student is notified

---

### User Story 2 - Chunk Documents for Retrieval (Priority: P2)

As a student, I want my documents to be automatically split into meaningful chunks so that when I ask questions, the AI can find the most relevant sections of my study materials.

**Why this priority**: Chunking enables semantic search by breaking large documents into digestible pieces. This is essential for accurate Q&A retrieval but depends on successful text extraction (P1).

**Independent Test**: Can be tested by uploading a multi-page document and verifying that it is split into multiple chunks with proper overlap and metadata. Each chunk should be independently retrievable.

**Acceptance Scenarios**:

1. **Given** a document with extracted text longer than the chunk size limit, **When** chunking runs, **Then** the text is split into overlapping chunks that preserve context
2. **Given** a short document (less than one chunk), **When** chunking runs, **Then** the entire document becomes a single chunk
3. **Given** a document with clear section breaks (headings), **When** chunking runs, **Then** chunks preferentially split at section boundaries to maintain semantic coherence

---

### User Story 3 - Generate Embeddings for Semantic Search (Priority: P3)

As a student, I want my document chunks to be converted into searchable embeddings so that the AI can understand the meaning of my content and find relevant answers to my questions.

**Why this priority**: Embeddings enable semantic similarity search, which powers intelligent Q&A. This is the final step before documents are query-ready, depending on both extraction and chunking.

**Independent Test**: Can be tested by uploading a document, waiting for processing, then performing a semantic search query to verify relevant chunks are returned based on meaning rather than keyword matching.

**Acceptance Scenarios**:

1. **Given** a document has been chunked, **When** embedding generation runs, **Then** each chunk has a vector embedding stored in the database
2. **Given** embeddings exist for a document, **When** a student asks a question related to the content, **Then** semantically similar chunks are retrievable (validated in future Q&A feature)
3. **Given** embedding generation fails (e.g., AI service unavailable), **When** the task retries, **Then** it resumes from the last successful chunk without reprocessing completed chunks

---

### User Story 4 - Track Document Processing Status (Priority: P2)

As a student, I want to see the processing status of my uploaded documents so that I know when they are ready for Q&A and can troubleshoot any issues.

**Why this priority**: Visibility into processing status is critical for user trust and debugging. Students need to know if their documents are ready or if something went wrong. Tied to P2 as it spans all processing stages.

**Independent Test**: Can be tested by uploading a document and observing status transitions in the UI from "uploaded" through "extracting," "chunking," "embedding," to "ready" or "error."

**Acceptance Scenarios**:

1. **Given** a document has been uploaded, **When** the student views their document list, **Then** they see the current processing status (e.g., "Processing", "Ready", "Error")
2. **Given** a document encounters an error during processing, **When** the student views details, **Then** they see a user-friendly error message explaining what went wrong
3. **Given** a document is still processing, **When** the student views progress, **Then** they see which stage (extraction, chunking, embedding) is currently active

---

### Edge Cases

- What happens when a document exceeds the maximum file size (100MB)?
  - Upload is rejected with a clear error message before processing begins
- What happens when a PDF contains only images (no extractable text)?
  - Document is marked as "no text content" with a suggestion to use OCR-enabled upload (future feature)
- How does the system handle duplicate document uploads?
  - Existing `contentHash` and `uniqueIdentifierHash` prevent duplicate processing; user is notified of existing document
- What happens if the embedding service is rate-limited?
  - Processing pauses and resumes with exponential backoff; partial progress is preserved
- How are documents in unsupported languages handled?
  - Text is extracted regardless of language; embedding model handles multilingual content

## Requirements _(mandatory)_

### Functional Requirements

- **FR-001**: System MUST extract plain text content from PDF files using a document parsing library
- **FR-002**: System MUST extract plain text content from DOC and DOCX (Microsoft Word) files
- **FR-003**: System MUST extract content from plain text files (TXT, MD) by reading file contents directly
- **FR-004**: System MUST split extracted text into chunks with configurable size (default: 1000 characters) and overlap (default: 200 characters)
- **FR-005**: System MUST preserve chunk metadata including source document ID, chunk index, and character offsets
- **FR-006**: System MUST generate vector embeddings for each chunk using an AI embedding model
- **FR-007**: System MUST store embeddings in a vector-enabled database column for similarity search
- **FR-008**: System MUST track document processing status with states: UPLOADED, EXTRACTING, CHUNKING, EMBEDDING, READY, ERROR
- **FR-009**: System MUST update document status in real-time as processing progresses through each stage
- **FR-010**: System MUST record error details when processing fails at any stage
- **FR-011**: System MUST retry failed processing steps with exponential backoff (max 3 attempts)
- **FR-012**: System MUST process documents asynchronously using background tasks to avoid blocking user interactions
- **FR-013**: System MUST validate file types before processing and reject unsupported formats with clear error messages

### Key Entities

- **Document**: Represents an uploaded file with metadata (title, type, file URL, processing status). Extended with status tracking and extracted content reference.
- **DocumentChunk**: A segment of extracted text from a document. Contains chunk text, position metadata (index, offsets), and reference to parent document.
- **ChunkEmbedding**: Vector representation of a document chunk. Contains the embedding vector and reference to the source chunk for retrieval.

## Success Criteria _(mandatory)_

### Measurable Outcomes

- **SC-001**: Documents complete full ingestion pipeline (upload â†’ ready) within 2 minutes for files under 10MB
- **SC-002**: Text extraction accuracy exceeds 95% for standard PDF and DOCX files (measured by character-level comparison with source)
- **SC-003**: 99% of successfully uploaded documents reach "Ready" status without manual intervention
- **SC-004**: Processing failures display actionable error messages within 5 seconds of failure detection
- **SC-005**: System handles 50 concurrent document uploads without processing queue degradation
- **SC-006**: Students can identify document processing status within 1 second of viewing document list

## Assumptions

- The pgvector extension will be available in PostgreSQL for vector storage and similarity search
- An AI embedding model (via LangChain SDK) is available and configured for generating embeddings
- Existing R2 storage infrastructure continues to be used for file storage
- Trigger.dev background task system handles async processing as currently implemented
- Document chunking parameters (size, overlap) can use sensible defaults initially and be tuned later based on Q&A performance
